<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Publications (sorted by dates)</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Yifei Wang</div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="news.html">News</a></div>
<div class="menu-category">Publications</div>
<div class="menu-item"><a href="publications_topic.html">sorted&nbsp;by&nbsp;topics</a></div>
<div class="menu-item"><a href="publications_date.html" class="current">sorted&nbsp;by&nbsp;dates</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Publications (sorted by dates)</h1>
</div>
<h2>Journal</h2>
<ul>
<li><p><b>Yifei Wang</b>, Yixuan Hua, Emmanuel Candes, Mert Pilanci, <b>Overparameterized ReLU Neural Networks Learn the Simplest Models: Neural Isometry and Exact Recovery</b>, IEEE transactions on Information Theory, <a href="https://arxiv.org/abs/2209.15265">(paper)</a>, <a href="https://github.com/pilancilab/Neural-recovery">(code)</a> </p>
</li>
<li><p><b>Yifei Wang</b>, Peng Chen, Mert Pilanci, Wuchen Li, <b>Optimal Neural Network Approximation of Wasserstein Gradient Direction via Convex Optimization</b>, to appear on SIAM Journal on Mathematics of Data Science 2024 <a href="https://arxiv.org/pdf/2205.13098.pdf">(paper)</a></p>
</li>
<li><p><b>Yifei Wang</b>, Mert Pilanci, <b>Sketching the Krylov Subspace: Faster Computation of the Entire Ridge Regularization path</b>, Journal of Supercomputing 2023. <a href="https://arxiv.org/pdf/2210.12212.pdf">(paper)</a>, <a href="https://github.com/pilancilab/IHS-BIN">(code)</a> </p>
</li>
<li><p><b>Yifei Wang</b>, Kangkang Deng, Haoyang Li, Zaiwen Wen, <b>A Decomposition Augmented Lagrangian Method for Low-rank Semidefinite Programming</b>, SIAM on Optimization (2023)<a href="https://arxiv.org/abs/2109.11707">(paper)</a></p>
</li>
<li><p><b>Yifei Wang</b>, Peng Chen, Wuchen Li, <b>Projected Wasserstein gradient descent for high-dimensional Bayesian inference</b>, SIAM on Uncertainty Quantification (2022) <a href="https://arxiv.org/abs/2102.06350">(paper)</a>, <a href="https://github.com/cpempire/pWGD">(code)</a>, <a href="https://siammds22.us2.pathable.com/meetings/virtual/7EAHyezWq7gLK9KSH">(talk video at SIAM MDS22)</a></p>
</li>
<li><p><b>Yifei Wang</b>, Zeyu Jia, Zaiwen Wen, <b>Search Direction Correction with Normalized Gradient Makes First-Order Methods Faster</b>, SIAM on Scientific Computing (2021), Vol. 43, No. 5, pp. A3184-A3211, <a href="https://yiifeiwang.github.io/files/search_direction_correction.pdf">(paper)</a></p>
</li>
<li><p><b>Yifei Wang</b>, Wuchen Li, <b>Accelerated Information Gradient flow</b>, Journal of Scientific Computing (2022), <a href="https://doi.org/10.1007/s10915-021-01709-3">(paper)</a>, <a href="https://sites.google.com/view/acc-info-grad/home">(website)</a>, <a href="https://github.com/YiifeiWang/Accelerated-Information-Gradient-flow">(code)</a>.</p>
</li>
</ul>
<h2>Conference</h2>
<ul>
<li><p>Ertem Nusret Tas, David Tse, <b>Yifei Wang</b>, <b>A Circuit Approach to Constructing Blockchains on Blockchains</b>, <a href="https://arxiv.org/abs/2402.00220">(paper)</a>, Advances in Financial Technologies (AFT) 2024.</p>
</li>
</ul>
<ul>
<li><p><b>Yifei Wang</b>, Tolga Ergen, Mert Pilanci, <b>Parallel Deep Neural Networks Have Zero Duality Gap</b>, International Conference on Learning Representations (ICLR) 2023 Poster <a href="https://openreview.net/forum?id=6zrOr_Rdhjs">(paper)</a></p>
</li>
</ul>
<ul>
<li><p><b>Yifei Wang</b>, Tavor Baharav, Yanjun Han, Jiantao Jiao, David Tse, <b>Beyond the Best: Distribution Functional Estimation in Infinite-Armed Bandits</b>, Conference on Neural Information Processing Systems (NeurIPS) 2022, <a href="https://openreview.net/forum?id=q16HXpXtjJn">(paper)</a></p>
</li>
</ul>
<ul>
<li><p><b>Yifei Wang</b>, Jonathan Lacotte, Mert Pilanci, <b>The Hidden Convex Optimization Landscape of Two-Layer ReLU Neural Networks: an Exact Characterization of the Optimal Solutions</b>, International Conference on Learning Representations (ICLR) 2022 Oral, <a href="https://openreview.net/forum?id=Z7Lk2cQEG8a">(paper)</a> </p>
</li>
</ul>
<ul>
<li><p><b>Yifei Wang</b>, Mert Pilanci, <b>The Convex Geometry of Backpropagation: Neural Network Gradient Flows Converge to Extreme Points of the Dual Convex Program</b>, International Conference on Learning Representations (ICLR) 2022 Poster, <a href="https://arxiv.org/abs/2110.06488">(paper)</a></p>
</li>
</ul>
<ul>
<li><p>Jonathan Lacotte, <b>Yifei Wang</b>, Mert Pilanci, <b>Adaptive Newton Sketch: Linear-time Optimization with Quadratic Convergence and Effective Hessian Dimensionality</b>, International Conference on Machine Learning (ICML) 2021 Poster, <a href="http://proceedings.mlr.press/v139/lacotte21a/lacotte21a.pdf">(paper)</a>, <a href="https://github.com/pilancilab/Adaptive-Newton-Sketch">(code)</a></p>
</li>
</ul>
<h2>Preprints</h2>
<ul>
<li><p><b>Yifei Wang</b>, Sungyoon Kim, Paul Chu, Indu Subramaniam, Mert Pilanci, <b>Randomized Geometric Algebra Methods for Convex Neural Networks</b>, <a href="https://arxiv.org/abs/2406.02806">(paper)</a></p>
</li>
</ul>
<ul>
<li><p>Emi Zeger, <b>Yifei Wang</b>, Aaron Mishkin, Tolga Ergen, Emmanuel Candes, Mert Pilanci, <b>A Library of Mirrors: Deep Neural Nets in Low Dimensions are Convex Lasso Models with Reflection Features</b>, <a href="https://arxiv.org/pdf/2403.01046.pdf">(paper)</a> </p>
</li>
</ul>
<ul>
<li><p><b>Yifei Wang</b>, Mert Pilanci, <b>Polynomial-Time Solutions for ReLU Network Training: A Complexity Classification via Max-Cut and Zonotopes</b>, <a href="https://arxiv.org/abs/2311.10972">(paper)</a> </p>
</li>
</ul>
<ul>
<li><p>Alex Leviyev, Joshua Chen, <b>Yifei Wang</b>, Omar Ghattas, Aaron Zimmerman, <b>A stochastic Stein variational Newton Method</b>, <a href="https://arxiv.org/pdf/2204.09039.pdf">(paper)</a>, <a href="https://github.com/leviyevalex/sSVN">(code)</a> </p>
</li>
</ul>
<ul>
<li><p><b>Yifei Wang</b>, Wuchen Li, <b>Information Newton's flow: second-order optimization method in probability space</b>, <a href="https://arxiv.org/pdf/2001.04341">(paper)</a>, <a href="https://github.com/YiifeiWang/Information-Newton-flow">(code)</a></p>
</li>
</ul>
<div id="footer">
<div id="footer-text">
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
